{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on LFW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to evaluate the clustering algorithm on the Labeled Faces In the Wild dataset which can be  \n",
    "found [here](http://vis-www.cs.umass.edu/lfw/)  \n",
    "The dataset has about 13,233 images of 5749 people where there are 1680 people with two or more images.\n",
    "\n",
    "Before running this notebook it is essential to run the `embedder.py`. On doing so all the embeddings for faces in the dataset are computed and saved into a pickle file. This notebook loads that pickle file and runs the clustering algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "from random import shuffle\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing chinese whispers algorithm\n",
    "As we have already defined the clustering algorithm in `clusterer.py` we can directly import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CW import draw_graph\n",
    "from CW import chinese_whispers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings for the faces in the dataset (LFW in this case) should be loaded. The embeddings can be computed from the script\n",
    "`embedder.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for nCr\n",
    "def nCr(n,r):\n",
    "    fact = math.factorial\n",
    "    return fact(n)/(fact(r)*fact(n-r))\n",
    "# Partially view a dictionary with pretty printing\n",
    "def partial_dict_view(dictionary,n):\n",
    "    pp.pprint({k: v for i, (k, v) in enumerate(dictionary.items()) if i < n})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Chinese Whispers on the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"embeddings.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the embeddings are loaded we can then create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating graph: 100%|███████████████████████████████████████████████████████████▉| 14035/14036 [03:23<00:00, 69.09it/s]\n",
      "Iterations: 100%|██████████████████████████████████████████████████████████████████████| 30/30 [00:34<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "graph = draw_graph(data,0.67)\n",
    "graph = chinese_whispers(graph,30)\n",
    "# Takes about 5 minutes for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the clustering we need to define a few things.\n",
    "First we calculate true pairwise positives,true pairwise negatives, false pairwise positives false pairwise negatives by compairing pairs of nodes.\n",
    "For a cluster the correct decisions are when:\n",
    "- **true pairwise positives (TP)**: when two nodes belonging to same class also belong to same cluster\n",
    "- **true pairwise negatives (TN)**: when two nodes of different classes belong to different clusters\n",
    "and incorrect decisions are:\n",
    "- **false pairwise positives (FP)**: when two nodes of different classes belong to same cluster\n",
    "- **false pairwise negatives (FN)**: when two nodes of same class belong to different clusters\n",
    "\n",
    "So in case of clustering instead of looking at individual data points, pairs of datapoints are studied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we calculate the precision and recall as:  \n",
    "  \n",
    "$Precision = \\frac{TP}{TP+FP} $  \n",
    "  \n",
    "$Recall = \\frac{TP}{TP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metric used is the F-score.  \n",
    "F-score is defined as the harmonic mean of precision and recall.\n",
    "\n",
    "$ F-measure =  \\frac{2*Precision*Recall}{Precision+Recall}$\n",
    "\n",
    "We will first calculate the precision and recall using True positives, False positives and False negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly create a dictionary which maps a cluster to the number of images it contains.  \n",
    "**NOTE:** a lot of people in the LFW dataset have only one image of them, hence there can be many clusters with only one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_num_images = {}\n",
    "for node in graph.nodes:\n",
    "    if graph.nodes[node]['cluster'] in cluster_to_num_images:\n",
    "        cluster_to_num_images[graph.nodes[node]['cluster']] += 1\n",
    "    else:\n",
    "        cluster_to_num_images[graph.nodes[node]['cluster']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Person 1': 1,\n",
      " 'Person 10': 2,\n",
      " 'Person 11159': 2,\n",
      " 'Person 12187': 2,\n",
      " 'Person 13905': 8,\n",
      " 'Person 14': 1,\n",
      " 'Person 3': 1,\n",
      " 'Person 5439': 4,\n",
      " 'Person 6': 4,\n",
      " 'Person 8': 1}\n"
     ]
    }
   ],
   "source": [
    "partial_dict_view(cluster_to_num_images,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the total positives  \n",
    "  \n",
    "The number of pairs formed within a cluster having $n$ nodes is given by ${n \\choose 2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pw_positives = 0\n",
    "for cluster,num_images in cluster_to_num_images.items():\n",
    "    # It's a positive only if a pair can be formed\n",
    "    if num_images >= 2:\n",
    "        total_pw_positives += nCr(num_images,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265384.0\n"
     ]
    }
   ],
   "source": [
    "print(total_pw_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The subdirectory of the image in which it resides in the LFW folder is the identity of the person. \n",
    "- In this scenario the identity is the class.\n",
    "- Hence the  classes can be taken from the subdirectory in the path of the image.\n",
    "- The nodes of the networkx graph contain an attribute which has the relative path for the image.\n",
    "- For example `lfw\\\\Aaron_Eckhart\\\\Aaron_Eckhart_0001.jpg` is the image corresponding to the person named Aaron Eckhart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we create a dictionary which maps a cluster to a dictionary which describes the cluster. i.e the latter's value is a dictionary which maps each class (identity) in the cluster to the number of nodes (image embeddings) in the cluster which belong to that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(cluster_to_num_images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_desc = {}\n",
    "for cluster in clusters:\n",
    "    cluster_to_desc[cluster] = {}\n",
    "    for node in graph.nodes:\n",
    "        if graph.nodes[node]['cluster'] == cluster:\n",
    "            \n",
    "            path = os.path.normpath(graph.nodes[node]['source'])\n",
    "            class_ = path.split(os.sep)[1]\n",
    "            # find a cleaner implementation\n",
    "            if class_ not in cluster_to_desc[cluster]:\n",
    "                cluster_to_desc[cluster][class_] = 1\n",
    "            else:\n",
    "                cluster_to_desc[cluster][class_] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Person 1': {'Aaron_Eckhart': 1},\n",
      " 'Person 12187': {'Aaron_Guiel': 1, 'Shane_Phillips': 1},\n",
      " 'Person 3': {'Aaron_Patterson': 1},\n",
      " 'Person 6': {'Aaron_Peirsol': 4},\n",
      " 'Person 8': {'Aaron_Pena': 1}}\n"
     ]
    }
   ],
   "source": [
    "# Detailed description of the dictionary\n",
    "partial_dict_view(cluster_to_desc,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the true pairwise positives.    \n",
    "True pairwise positives are basically the number of pairs formed between two nodes in the cluster\n",
    "which belong to the same class.\n",
    "\n",
    "For example in the dictionary above the class Aaron Peirsol has 4 images of him in cluster number 7.  \n",
    "  \n",
    "Hence ${4 \\choose 2}$ pairs (true pairwise positives) can be formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pw_positives = 0\n",
    "for cluster in cluster_to_desc.keys():\n",
    "    for class_ in cluster_to_desc[cluster].keys():\n",
    "        if cluster_to_desc[cluster][class_] >= 2:\n",
    "            true_pw_positives += nCr(cluster_to_desc[cluster][class_],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238554.0\n"
     ]
    }
   ],
   "source": [
    "print(true_pw_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False positives can then be calculated from subtracting from the total pairwise positives.  \n",
    "  \n",
    "$FP = Total Positives - TP$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26830.0\n"
     ]
    }
   ],
   "source": [
    "false_pw_positives = total_pw_positives - true_pw_positives\n",
    "print(false_pw_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a dictionary which maps a class(identity) to the number of images it contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_num_images = {}\n",
    "for class_ in os.listdir(\"lfw\"):\n",
    "    num_images = 0\n",
    "    for image in os.listdir(os.path.join(\"lfw\",class_)):\n",
    "        num_images += 1\n",
    "    class_to_num_images[class_] = num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aaron_Eckhart': 1,\n",
      " 'Aaron_Guiel': 1,\n",
      " 'Aaron_Patterson': 1,\n",
      " 'Aaron_Peirsol': 4,\n",
      " 'Aaron_Pena': 1,\n",
      " 'Aaron_Sorkin': 2,\n",
      " 'Aaron_Tippin': 1,\n",
      " 'Abba_Eban': 1,\n",
      " 'Abbas_Kiarostami': 1,\n",
      " 'Abdel_Aziz_Al-Hakim': 1}\n"
     ]
    }
   ],
   "source": [
    "partial_dict_view(class_to_num_images,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate the false negatives using the above dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pw_negatives = 0\n",
    "# Iterate through all classes\n",
    "for class_ in class_to_num_images.keys():\n",
    "    prev_occurence = 0\n",
    "    for cluster in cluster_to_num_images.keys():\n",
    "        if class_ in cluster_to_desc[cluster]:\n",
    "            # Get the number of nodes for the current class in the cluster\n",
    "            num_of_class_in_cluster = cluster_to_desc[cluster][class_]\n",
    "            \n",
    "            # Get the number of nodes for the current class not in the cluster\n",
    "            # It can be calculated by subtracting the number of times a class occurs in the cluster\n",
    "            # from the total number of times it occurs in the dataset\n",
    "            num_of_class_out_of_cluster = class_to_num_images[class_] - num_of_class_in_cluster\n",
    "            \n",
    "            # The number of pairs formed containing mismatched nodes is the number of nodes in\n",
    "            # the cluster multiplied with the number out of the cluster\n",
    "            # To account for pairs added by the previous cluster we subtract 'prev'\n",
    "            false_pw_negatives += num_of_class_in_cluster*(num_of_class_out_of_cluster-prev_occurence)\n",
    "            prev_occurence += num_of_class_in_cluster\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054\n"
     ]
    }
   ],
   "source": [
    "print(false_pw_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally with all these values we can calculate the F-measure.  \n",
    "  \n",
    "$ F-measure =  \\frac{2*Precision*Recall}{Precision+Recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.899\n",
      "Recall: 0.996\n",
      "F-measure: 0.945\n"
     ]
    }
   ],
   "source": [
    "precision = true_pw_positives / (true_pw_positives + false_pw_positives)\n",
    "\n",
    "recall = true_pw_positives / (true_pw_positives + false_pw_negatives)\n",
    "\n",
    "f_measure = (2*precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F-measure: {:.3f}\".format(f_measure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision vs Recall\n",
    "\n",
    "Note that with a threshold value of `0.65` we were able to get a higher recall. Increasing the threshold value results in a higher precision but a lower recall. Since the task was to get all the images corresponding to a person in a corpus of photos a higher recall value was preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5749 people in the lfw dataset. Let's check number of people (clusters) the algorithm gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6090\n"
     ]
    }
   ],
   "source": [
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the LFW dataset is divided into 5749 subdirectories each indicating a single person, there are many images where there are more than one face. But for these types of images only a single label is used. This can either result in two scenarios:\n",
    "1. The identity of the extra face detected is nowhere present in the dataset. This can result in a seperate cluster. This results in a slightly higher number of clusters formed (close to 6000 in this case). \n",
    "  \n",
    "2. The identity of the extra face detected in the image is present in the dataset, but the label corresponding to the image is different. In this case the face is assigned to the respective cluster, but while evaluating using this notebook it might be labeled as a false positive.\n",
    "\n",
    "But even with these constraints the algorithm seems to have good results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Different precision, recall and f-measure is obtained for every run of the clustering algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-cpu] *",
   "language": "python",
   "name": "conda-env-tensorflow-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
