{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "from random import shuffle\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing chinese whispers algorithm\n",
    "As we have already defined the clustering algorithm in `clusterer.py` we can directly import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clusterer import chineseWhispers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings for the faces in the dataset (LFW in this case) should be loaded. The embeddings can be computed from the script\n",
    "`embedder.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Chinese Whispers on the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"embeddings_pool.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the embeddings are loaded we can then create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = chineseWhispers(data,0.8,20)\n",
    "# Takes about 5 minutes for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metric used is the F-score.  \n",
    "F-score is defined as the harmonic mean of precision and recall.\n",
    "\n",
    "F-score = (2*precison*recall)/(precision + recall) \n",
    "(Replace with latex later)\n",
    "\n",
    "We will first calculate the precision and recall using True positives, False positives and False negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for nCr\n",
    "def nCr(n,r):\n",
    "    fact = math.factorial\n",
    "    return fact(n)/(fact(r)*fact(n-r))\n",
    "\n",
    "def partial_dict_view(dictionary,n):\n",
    "    pp.pprint({k: v for i, (k, v) in enumerate(dictionary.items()) if i < n})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly create a dictionary which maps a cluster to the number of images it contains.  \n",
    "**NOTE:** a lot of people in the LFW dataset have only one image of them, hence there can be many clusters with only one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_num_images = {}\n",
    "for node in graph.nodes:\n",
    "    if graph.nodes[node]['pseudoClass'] in cluster_to_num_images:\n",
    "        cluster_to_num_images[graph.nodes[node]['pseudoClass']] += 1\n",
    "    else:\n",
    "        cluster_to_num_images[graph.nodes[node]['pseudoClass']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 7: 4}\n"
     ]
    }
   ],
   "source": [
    "partial_dict_view(cluster_to_num_images,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the total positives\n",
    "(add explanation later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pw_positives = 0\n",
    "for cluster,num_images in cluster_to_num_images.items():\n",
    "    # It's a positive only if a pair can be formed\n",
    "    if num_images >= 2:\n",
    "        total_pw_positives += nCr(num_images,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345969.0\n"
     ]
    }
   ],
   "source": [
    "print(total_pw_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The subdirectory of the image in which it resides in the LFW folder is the identity of the person. \n",
    "- In this scenario the identity is the class.\n",
    "- Hence the  classes can be taken from the subdirectory in the path of the image.\n",
    "- The nodes of the networkx graph contain an attribute which has the relative path for the image.\n",
    "- For example `lfw\\\\Aaron_Eckhart\\\\Aaron_Eckhart_0001.jpg` is the image corresponding to the person named Aaron Eckhart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we create a dictionary which maps a cluster to a dictionary which describes the cluster. i.e the latter's value is a dictionary which maps each class (identity) in the cluster to the number of nodes (image embeddings) in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(cluster_to_num_images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_desc = {}\n",
    "for cluster in clusters:\n",
    "    cluster_to_desc[cluster] = {}\n",
    "    for node in graph.nodes:\n",
    "        if graph.nodes[node]['pseudoClass'] == cluster:\n",
    "            \n",
    "            Class = os.path.split(graph.nodes[node]['path'])[0]\n",
    "            Class = Class[4:]\n",
    "            # find a cleaner implementation\n",
    "            if Class not in cluster_to_desc[cluster]:\n",
    "                cluster_to_desc[cluster][Class] = 1\n",
    "            else:\n",
    "                cluster_to_desc[cluster][Class] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'AJ_Cook': 1},\n",
      " 2: {'AJ_Lamas': 1},\n",
      " 3: {'Aaron_Eckhart': 1},\n",
      " 4: {'Aaron_Guiel': 1},\n",
      " 5: {'Aaron_Patterson': 1},\n",
      " 7: {'Aaron_Peirsol': 4},\n",
      " 12: {'Aaron_Sorkin': 2},\n",
      " 5040: {'Abba_Eban': 1,\n",
      "        'Bernard_Landry': 1,\n",
      "        'Bobby_Bowden': 1,\n",
      "        'Cass_Ballenger': 1,\n",
      "        'Charles_Chandler_IV': 1,\n",
      "        'Donald_Keck': 1,\n",
      "        'Edward_Egan': 1,\n",
      "        'Gene_Robinson': 1,\n",
      "        'George_Brumley': 1,\n",
      "        'Hans_Blix': 38,\n",
      "        'Ignacio_Antonio_Velasco': 1,\n",
      "        'Itzhak_Perlman': 1,\n",
      "        'Jesse_Helms': 1,\n",
      "        'Jim_Talent': 1,\n",
      "        'Kenneth_Reichert': 1,\n",
      "        'Larry_Tanenbaum': 1,\n",
      "        'Michael_J_Sheehan': 2,\n",
      "        'Miguel_Aldana_Ibarra': 1,\n",
      "        'Pedro_Malan': 2,\n",
      "        'Ray_Bradbury': 1,\n",
      "        'Robert_Gordon_Card': 1,\n",
      "        'Rupert_Murdoch': 1,\n",
      "        'Sidney_Kimmel': 1},\n",
      " 8682: {'Aaron_Tippin': 1, 'Marwan_Barghouthi': 2},\n",
      " 10467: {'Aaron_Pena': 1,\n",
      "         'Aram_Adler': 1,\n",
      "         'Martin_Torrijos': 1,\n",
      "         'Ray_Romano': 9}}\n"
     ]
    }
   ],
   "source": [
    "# Detailed description of the dictionary\n",
    "partial_dict_view(cluster_to_desc,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the true positives. (give explanation later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pw_positives = 0\n",
    "for cluster in cluster_to_desc.keys():\n",
    "    for Class in cluster_to_desc[cluster].keys():\n",
    "        if cluster_to_desc[cluster][Class] >= 2:\n",
    "            true_pw_positives += nCr(cluster_to_desc[cluster][Class],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236091.0\n"
     ]
    }
   ],
   "source": [
    "print(true_pw_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False positives can then be calculated from subtracting from the total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109878.0\n"
     ]
    }
   ],
   "source": [
    "false_pw_positives = total_pw_positives - true_pw_positives\n",
    "print(false_pw_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a dictionary which maps a class(identity) to the number of images it contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_num_images = {}\n",
    "for Class in os.listdir(\"lfw\"):\n",
    "    num_images = 0\n",
    "    for image in os.listdir(os.path.join(\"lfw\",Class)):\n",
    "        num_images += 1\n",
    "    class_to_num_images[Class] = num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aaron_Eckhart': 1,\n",
      " 'Aaron_Guiel': 1,\n",
      " 'Aaron_Patterson': 1,\n",
      " 'Aaron_Peirsol': 4,\n",
      " 'Aaron_Pena': 1,\n",
      " 'Aaron_Sorkin': 2,\n",
      " 'Aaron_Tippin': 1,\n",
      " 'Abba_Eban': 1,\n",
      " 'Abbas_Kiarostami': 1,\n",
      " 'Abdel_Aziz_Al-Hakim': 1}\n"
     ]
    }
   ],
   "source": [
    "partial_dict_view(class_to_num_images,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate the false negatives using the above dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pw_negatives = 0\n",
    "# Iterate through all classes\n",
    "for Class in class_to_num_images.keys():\n",
    "    prev_occurence = 0\n",
    "    for cluster in cluster_to_num_images.keys():\n",
    "        if Class in cluster_to_desc[cluster]:\n",
    "            # Get the number of nodes for the current class in the cluster\n",
    "            num_of_class_in_cluster = cluster_to_desc[cluster][Class]\n",
    "            \n",
    "            # Get the number of nodes for the current class not in the cluster\n",
    "            # It can be calculated by subtracting the number of times a class occurs in the cluster\n",
    "            # from the total number of times it occurs in the dataset\n",
    "            num_of_class_out_of_cluster = class_to_num_images[Class] - num_of_class_in_cluster\n",
    "            \n",
    "            # The number of pairs formed containing mismatched nodes is the number of nodes in\n",
    "            # the cluster multiplied with the number out of the cluster\n",
    "            # To account for pairs added by the previous cluster we subtract 'prev'\n",
    "            false_pw_negatives += num_of_class_in_cluster*(num_of_class_out_of_cluster-prev_occurence)\n",
    "            prev_occurence += num_of_class_in_cluster\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6166\n"
     ]
    }
   ],
   "source": [
    "print(false_pw_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-cpu] *",
   "language": "python",
   "name": "conda-env-tensorflow-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
